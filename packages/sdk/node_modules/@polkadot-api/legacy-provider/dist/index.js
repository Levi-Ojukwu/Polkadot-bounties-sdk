'use strict';

var utils = require('@polkadot-api/utils');
var rxjs = require('rxjs');
var rawClient = require('@polkadot-api/raw-client');
var substrateBindings = require('@polkadot-api/substrate-bindings');

const getBlocks = ({
  initial$,
  allHeads$,
  finalized$,
  getHeader$,
  hasher$,
  getRecursiveHeader
}) => {
  const finalizedhash$ = finalized$.pipe(rxjs.map((x) => x.hash));
  const blocks = /* @__PURE__ */ new Map();
  let prevFin = "";
  let finalized = "";
  let best = "";
  let activeSubscriptions = /* @__PURE__ */ new Set();
  const getTree = (root, result = []) => {
    result.push(root);
    blocks.get(root).children.forEach((c) => {
      getTree(c, result);
    });
    return result;
  };
  const getFinalizedEvent = () => {
    const prunedBlockHashes = [];
    const finalizedBlockHashes = [];
    let current = blocks.get(finalized);
    let prev = blocks.get(current.parent);
    while (prev) {
      finalizedBlockHashes.push(current.hash);
      prev.children.forEach((c) => {
        if (c !== current.hash) getTree(c, prunedBlockHashes);
      });
      current = prev;
      if (current.hash === prevFin) break;
      prev = blocks.get(current.parent);
    }
    finalizedBlockHashes.reverse();
    return { event: "finalized", prunedBlockHashes, finalizedBlockHashes };
  };
  const setBestFromFinalized = () => {
    best = finalized;
    let bestHeight = 0;
    getTree(finalized).map((x) => blocks.get(x)).forEach((x) => {
      if (x.number > bestHeight) {
        bestHeight = x.number;
        best = x.hash;
      }
    });
  };
  const addBlock = (block) => {
    const { hash, parent } = block;
    const me = {
      ...block,
      children: /* @__PURE__ */ new Set(),
      usages: /* @__PURE__ */ new Set()
    };
    blocks.set(hash, me);
    blocks.get(parent)?.children.add(hash);
    return me;
  };
  const ready$ = initial$.pipe(
    rxjs.withLatestFrom(finalizedhash$),
    rxjs.map(([initial, fin]) => {
      initial.forEach(addBlock);
      finalized = fin;
      setBestFromFinalized();
      return null;
    }),
    rxjs.shareReplay(1)
  );
  const getNewBlockEvent = (blockHash) => {
    const block = blocks.get(blockHash);
    activeSubscriptions.forEach((subId) => {
      block.usages.add(subId);
    });
    return {
      event: "newBlock",
      blockHash,
      parentBlockHash: block.parent,
      newRuntime: block.hasUpgrade ? {} : null
    };
  };
  const tryRemove = (blockHash, up) => {
    const block = blocks.get(blockHash);
    if (!block || block.usages.size > 0) return;
    const { parent, children } = block;
    if (up !== true) children.forEach((c) => tryRemove(c, false));
    if (up !== false) tryRemove(parent, true);
    if (!blocks.has(parent) || !block.children.size) {
      blocks.get(parent)?.children.delete(blockHash);
      blocks.delete(blockHash);
    }
  };
  const ignoreUntilReady = rxjs.filter(
    () => finalized !== ""
  );
  const isPresent = (blockHash) => blocks.has(blockHash);
  const allHeadsEvents$ = allHeads$.pipe(
    ignoreUntilReady,
    rxjs.concatMap(
      (newBlock) => isPresent(newBlock.parent) ? [newBlock] : getRecursiveHeader(newBlock.parent).pipe(
        rxjs.takeWhile((x) => !isPresent(x.parent), true),
        rxjs.toArray(),
        rxjs.mergeMap((blocks2) => [...blocks2.reverse(), newBlock])
      )
    ),
    rxjs.map((value) => ({ type: "new", value })),
    rxjs.share()
  );
  const finalizedEvents$ = finalizedhash$.pipe(
    rxjs.skip(1),
    ignoreUntilReady,
    rxjs.concatMap(
      (blockHash) => isPresent(blockHash) ? [blockHash] : (
        // it could happen that we are still loading the initial "new-blocks"
        allHeadsEvents$.pipe(
          rxjs.map(() => blockHash),
          rxjs.filter(isPresent),
          rxjs.take(1)
        )
      )
    ),
    rxjs.map((value) => ({ type: "fin", value }))
  );
  const updates$ = rxjs.merge(allHeadsEvents$, finalizedEvents$).pipe(
    rxjs.mergeMap((x) => {
      if (x.type === "new") {
        const block = x.value;
        const { hash } = block;
        addBlock(block);
        const result2 = [getNewBlockEvent(hash)];
        if (block.number > blocks.get(best).number) {
          best = hash;
          result2.push({ event: "bestBlockChanged", bestBlockHash: hash });
        }
        return result2;
      }
      prevFin = finalized;
      finalized = x.value;
      let prevBest = best;
      setBestFromFinalized();
      const result = [getFinalizedEvent()];
      if (prevBest !== best)
        result.unshift({ event: "bestBlockChanged", bestBlockHash: best });
      return result;
    }),
    rxjs.share()
  );
  const subscription = rxjs.merge(ready$, updates$).subscribe({
    error: rxjs.noop
    // the errors are propagated downstream
  });
  const upstream = (subId) => {
    const getInitialized = () => {
      const finalizedBlockHashes = [];
      let current = blocks.get(finalized);
      while (current && finalizedBlockHashes.length < 10) {
        finalizedBlockHashes.push(current.hash);
        current.usages.add(subId);
        current = blocks.get(current.parent);
      }
      finalizedBlockHashes.reverse();
      return {
        event: "initialized",
        finalizedBlockHashes
      };
    };
    const unpin = (blockHash) => {
      const block = blocks.get(blockHash);
      if (block) {
        block.usages.delete(subId);
        tryRemove(blockHash);
      }
    };
    const initialEvents$ = ready$.pipe(
      rxjs.mergeMap(() => {
        const others = getTree(
          finalized
        ).slice(1).map(getNewBlockEvent);
        if (others.length)
          others.push({
            event: "bestBlockChanged",
            bestBlockHash: best
          });
        return [getInitialized(), ...others];
      })
    );
    return {
      blocks$: rxjs.concat(initialEvents$, updates$).pipe(
        rxjs.tap({
          subscribe: () => {
            activeSubscriptions.add(subId);
          },
          finalize: () => {
            activeSubscriptions.delete(subId);
          }
        }),
        rxjs.share()
      ),
      getHeader: (blockHash) => blocks.get(blockHash)?.header ?? null,
      isPinned: (blockHash) => !!blocks.get(blockHash)?.usages.has(subId),
      unpin
    };
  };
  upstream.stop = () => {
    subscription.unsubscribe();
  };
  return {
    upstream,
    finalized$,
    getHeader$: (hash) => {
      const block = blocks.get(hash);
      return block ? rxjs.of(block) : getHeader$(hash);
    },
    hasher$
  };
};

const getFromShittyHeader = (hasher) => ({
  parentHash,
  number: rawNumber,
  stateRoot,
  extrinsicsRoot,
  digest
}) => {
  const number = Number(rawNumber);
  const rawDigests = digest.logs.map(utils.fromHex);
  const rawHeader = utils.mergeUint8([
    utils.fromHex(parentHash),
    substrateBindings.compact.enc(number),
    utils.fromHex(stateRoot),
    utils.fromHex(extrinsicsRoot),
    substrateBindings.compact.enc(digest.logs.length),
    ...rawDigests
  ]);
  return {
    parent: parentHash,
    hash: utils.toHex(hasher(rawHeader)),
    number,
    hasUpgrade: rawDigests.some(([x]) => x === 8),
    header: utils.toHex(rawHeader)
  };
};

const hashers = [substrateBindings.Blake2256, substrateBindings.Keccak256];
const fns = hashers.map(getFromShittyHeader);
const noHasher = (_) => {
  throw new Error("Hasher not supported");
};
const getHasherFromBlock = (shitHeader) => (hash) => hashers[fns.findIndex((fn) => fn(shitHeader).hash === hash)] || noHasher;

const withLatestFromBp = (latest$) => (base$) => new rxjs.Observable((observer) => {
  let latest;
  let prev = [];
  const subscription = base$.subscribe({
    next(v) {
      if (prev) prev.push(v);
      else observer.next([latest, v]);
    },
    error(e) {
      observer.error(e);
    },
    complete() {
      observer.complete();
    }
  });
  subscription.add(
    latest$.subscribe({
      next(v) {
        latest = v;
        if (prev) {
          const copy = [...prev];
          prev = null;
          copy.forEach((p) => observer.next([latest, p]));
        }
      },
      error(e) {
        observer.error(e);
      },
      complete() {
        if (prev) observer.error(new Error("Empty complete"));
      }
    })
  );
  return subscription;
});

const getUpstreamEvents = (request, request$) => {
  const firstFinHeader$ = new rxjs.Subject();
  const hasher$ = firstFinHeader$.pipe(
    rxjs.mergeMap(
      (h) => request$("chain_getBlockHash", [
        h.number
      ]).pipe(rxjs.map(getHasherFromBlock(h)))
    ),
    rxjs.shareReplay(1)
  );
  const fromShittyHeader$ = hasher$.pipe(
    rxjs.map(getFromShittyHeader),
    rxjs.shareReplay(1)
  );
  const toNiceHeader = rxjs.pipe(
    withLatestFromBp(fromShittyHeader$),
    rxjs.map(([fromShittyHeader, shitHeader]) => fromShittyHeader(shitHeader))
  );
  const getHeaders$ = (startMethod, stopMethod, isFin = false) => new rxjs.Observable((observer) => {
    const onError = (e) => {
      observer.error(e);
    };
    let stop = null;
    let isFirstFin = isFin;
    request(startMethod, [], {
      onSuccess: (subId, followSub) => {
        const done = followSub(subId, {
          next: (v) => {
            if (isFirstFin) {
              isFirstFin = false;
              firstFinHeader$.next(v);
              firstFinHeader$.complete();
            }
            observer.next(v);
          },
          error: onError
        });
        const unsubscribe = () => {
          done();
          try {
            request(stopMethod, [subId], {
              onError: utils.noop,
              onSuccess: utils.noop
            });
          } catch {
          }
        };
        if (stop !== null) unsubscribe();
        else stop = unsubscribe;
      },
      onError
    });
    return () => {
      stop?.();
      stop = utils.noop;
    };
  }).pipe(toNiceHeader);
  const allHeads$ = getHeaders$(
    "chain_subscribeAllHeads",
    "chain_unsubscribeAllHeads"
  ).pipe(rxjs.share());
  const finalized$ = getHeaders$(
    "chain_subscribeFinalizedHeads",
    "chain_unsubscribeFinalizedHeads",
    true
  ).pipe(rxjs.shareReplay(1));
  const getHeader$ = (hash) => request$("chain_getHeader", [hash]).pipe(
    toNiceHeader
  );
  const getRecursiveHeader = (hash) => getHeader$(hash).pipe(
    rxjs.mergeMap(
      (header) => rxjs.concat(rxjs.of(header), getRecursiveHeader(header.parent))
    )
  );
  const gap$ = rxjs.combineLatest([
    allHeads$.pipe(rxjs.take(1)),
    finalized$.pipe(rxjs.take(1))
  ]).pipe(
    rxjs.mergeMap(([latest, fin]) => {
      const nMissing = latest.number - fin.number - 1;
      return rxjs.concat(
        getRecursiveHeader(latest.parent).pipe(rxjs.take(Math.max(0, nMissing))),
        rxjs.of(fin)
      );
    }),
    rxjs.toArray(),
    rxjs.share()
  );
  const collected$ = allHeads$.pipe(rxjs.takeUntil(gap$), rxjs.toArray());
  const initial$ = rxjs.combineLatest([collected$, gap$]).pipe(
    rxjs.map(([collected, gap]) => [...gap.reverse(), ...collected])
  );
  return {
    initial$,
    allHeads$,
    finalized$,
    hasher$,
    getRecursiveHeader,
    getHeader$
  };
};

const getBlocks$ = (request, request$) => getBlocks(getUpstreamEvents(request, request$));

const createDescendantValues = (request) => {
  return (rootKey, at, onValues, onError, onDone) => {
    let isRunning = true;
    let areAllKeysDone = false;
    let onGoingValues = 0;
    const _onError = (e) => {
      if (isRunning) {
        isRunning = false;
        onError(e);
      }
    };
    const PAGE_SIZE = 1e3;
    const pullKeys = (startAtKey) => {
      request(
        "state_getKeysPaged",
        [rootKey, PAGE_SIZE, startAtKey || void 0, at],
        (result) => {
          if (!isRunning) return;
          if (result.length > 0) {
            onGoingValues++;
            request(
              "state_queryStorageAt",
              [result, at],
              ([{ changes }]) => {
                if (!isRunning) return;
                onGoingValues--;
                onValues(changes);
                if (areAllKeysDone && !onGoingValues) onDone();
              },
              _onError
            );
          }
          if (result.length < PAGE_SIZE) {
            areAllKeysDone = true;
            if (!onGoingValues) onDone();
          } else pullKeys(result.at(-1));
        },
        _onError
      );
    };
    pullKeys();
    return () => {
      isRunning = false;
    };
  };
};

const createClosestDescendantMerkleValue = (obsRequest) => (at, key) => obsRequest("state_getReadProof", [[key], at]).pipe(
  rxjs.mergeMap((x) => {
    const result = substrateBindings.validateProofs(x.proof);
    if (!result) throw new Error("Invalid Proof");
    const { rootHash, proofs } = result;
    let winnerHash = rootHash;
    let current = proofs[winnerHash];
    let nKeyChars = 2;
    do {
      const nextOne = proofs[winnerHash];
      if (!nextOne || nextOne.type === "Raw") break;
      current = nextOne;
      winnerHash = void 0;
      if (!current.partialKey.startsWith(
        key.slice(nKeyChars, nKeyChars + current.partialKey.length)
      ))
        return [];
      nKeyChars += current.partialKey.length;
      if ((current.type === "LeafWithHash" || current.type === "BranchWithHash") && proofs[current.value]) {
        winnerHash = current.value;
        continue;
      }
      if ("children" in current) {
        const winner = Object.entries(
          current.children
        ).find(([, hash]) => proofs[hash]);
        if (winner) {
          if (winner[0] !== key[nKeyChars++]) return [];
          winnerHash = winner[1];
        }
      }
    } while (winnerHash);
    return [current.hash];
  })
);

const createUpstream = (provider) => {
  const { request, disconnect } = rawClient.createClient(provider);
  const simpleRequest = (method, params, onSuccess, onError) => request(method, params, { onSuccess, onError });
  const obsRequest = (method, params) => new rxjs.Observable(
    (observer) => simpleRequest(
      method,
      params,
      (v) => {
        observer.next(v);
        observer.complete();
      },
      (e) => {
        observer.error(e);
      }
    )
  );
  const {
    upstream: getBlocks,
    finalized$,
    getHeader$,
    hasher$
  } = getBlocks$(request, obsRequest);
  const runtimeCall = (atBlock, method, data) => obsRequest("state_call", [
    method,
    data,
    atBlock
  ]);
  const innerStgDescendantVals = createDescendantValues(simpleRequest);
  const stgDescendantValues = (at, rootKey) => new rxjs.Observable(
    (observer) => innerStgDescendantVals(
      rootKey,
      at,
      (values) => {
        observer.next(values);
      },
      (e) => {
        observer.error(e);
      },
      () => {
        observer.complete();
      }
    )
  );
  const stgDescendantHashes = (at, rootKey) => stgDescendantValues(at, rootKey).pipe(
    withLatestFromBp(hasher$),
    rxjs.map(
      ([hasher, results]) => results.map(
        ([key, value]) => [key, utils.toHex(hasher(utils.fromHex(value)))]
      )
    )
  );
  const stgClosestDescendant = createClosestDescendantMerkleValue(obsRequest);
  const [stgValue, stgHash] = ["state_getStorage", "state_getStorageHash"].map(
    (method) => (atBlock, key) => obsRequest(method, [
      key,
      atBlock
    ])
  );
  const methods = obsRequest("rpc_methods", []);
  const chainName = obsRequest("system_name", []);
  const properties = obsRequest("system_properties", []);
  const getBody = (at) => obsRequest(
    "chain_getBlock",
    [at]
  );
  const getBlockHash$ = (height) => obsRequest("chain_getBlockHash", [height]);
  const genesisHash = getBlockHash$(0);
  return {
    getBlocks,
    finalized$,
    getBlockHash$,
    getHeader$,
    stgValue,
    stgHash,
    stgDescendantValues,
    stgDescendantHashes,
    stgClosestDescendant,
    runtimeCall,
    getBody,
    chainName,
    properties,
    genesisHash,
    disconnect,
    methods,
    request: simpleRequest,
    obsRequest
  };
};

const chainSpecMethods = Object.fromEntries(
  ["chainName", "genesisHash", "properties"].map(
    (key) => [key, `chainSpec_v1_${key}`]
  )
);
const createChainSpec = (upstream, reply, err) => {
  return (rId, method) => {
    const [, , name] = method.split("_");
    const observable = upstream[name];
    if (!observable) throw null;
    observable.subscribe(
      (result) => {
        reply(rId, result);
      },
      (e) => {
        console.error(e);
        err(rId, -32602, "Invalid");
      }
    );
  };
};

let latestId = 1;
const createOpaqueToken = () => {
  return `${latestId++}${Date.now()}`;
};

const validStorageTypes = /* @__PURE__ */ new Set([
  "value",
  "hash",
  "closestDescendantMerkleValue",
  "descendantsValues",
  "descendantsHashes"
]);
const areItemsValid = (items) => Array.isArray(items) && items.every(
  (x) => typeof x === "object" && typeof x.key === "string" && validStorageTypes.has(x.type)
);
const getStg$ = (upstream, at, items) => rxjs.merge(
  ...items.map(({ key, type }) => {
    switch (type) {
      case "value":
        return upstream.stgValue(at, key).pipe(
          rxjs.filter(Boolean),
          rxjs.map((value) => [
            {
              key,
              value
            }
          ])
        );
      case "hash":
        return upstream.stgHash(at, key).pipe(
          rxjs.filter(Boolean),
          rxjs.map((hash) => [
            {
              key,
              hash
            }
          ])
        );
      case "descendantsValues":
        return upstream.stgDescendantValues(at, key).pipe(
          rxjs.map((values) => values.map(([key2, value]) => ({ key: key2, value })))
        );
      case "descendantsHashes":
        return upstream.stgDescendantHashes(at, key).pipe(rxjs.map((values) => values.map(([key2, hash]) => ({ key: key2, hash }))));
      case "closestDescendantMerkleValue":
        return upstream.stgClosestDescendant(at, key).pipe(
          rxjs.filter(Boolean),
          rxjs.map((closestDescendantMerkleValue) => [
            {
              key,
              closestDescendantMerkleValue
            }
          ])
        );
    }
  })
);

const chainHeadMethods = Object.fromEntries(
  [
    "body",
    "call",
    "continue",
    "follow",
    "header",
    "stopOperation",
    "storage",
    "unfollow",
    "unpin"
  ].map((key) => [key, `chainHead_v1_${key}`])
);
const createChainHead = (upstream, reply, err, notification) => {
  const subscriptions = /* @__PURE__ */ new Map();
  const follow = (rId) => {
    if (subscriptions.size === 2) {
      return err(rId, -32800, "Limit reached");
    }
    const token = createOpaqueToken();
    const up = upstream.getBlocks(token);
    const operations = /* @__PURE__ */ new Map();
    subscriptions.set(token, {
      id: token,
      up,
      operations,
      cleanUp: () => {
        cleanUp();
      }
    });
    let cleanUp = utils.noop;
    reply(rId, token);
    let subscription = up.blocks$.subscribe({
      next(v) {
        notification("chainHead_v1_followEvent", token, v);
      },
      error(e) {
        console.error(e);
        cleanUp();
        notification("chainHead_v1_followEvent", token, { event: "stop" });
      }
    });
    cleanUp = () => {
      cleanUp = utils.noop;
      subscription?.unsubscribe();
      subscription = null;
      operations.forEach((cb) => {
        cb();
      });
      operations.clear();
      subscriptions.delete(token);
    };
    if (subscription.closed) cleanUp();
  };
  const unfollow = (rId, followId) => {
    subscriptions.get(followId)?.cleanUp();
    reply(rId, "null");
  };
  const stopOperation = (rId, followId, operationId) => {
    const cb = subscriptions.get(followId)?.operations.get(operationId);
    if (cb) cb();
    reply(rId, "null");
  };
  const header = ({ up: { getHeader } }, reply2, at) => {
    reply2(getHeader(at));
  };
  const unpin = ({ up: { unpin: innerUnpin } }, reply2, hashOrHashes) => {
    const hashes = typeof hashOrHashes === "string" ? [hashOrHashes] : hashOrHashes;
    hashes.forEach(innerUnpin);
    reply2(null);
  };
  const call = ({ operations, id: followId }, reply2, at, method, args) => {
    const operationId = createOpaqueToken();
    reply2({ result: "started", operationId });
    const subscription = upstream.runtimeCall(at, method, args).subscribe(
      (output) => {
        operations.delete(operationId);
        notification("chainHead_v1_call", followId, {
          event: "operationCallDone",
          operationId,
          output
        });
      },
      (e) => {
        operations.delete(operationId);
        console.error(e);
        notification("chainHead_v1_call", followId, {
          event: "operationError",
          operationId,
          error: ""
          // TODO: figure this out
        });
      }
    );
    if (!subscription.closed)
      operations.set(operationId, () => {
        subscription.unsubscribe();
        operations.delete(operationId);
      });
  };
  const body = ({ operations, id: followId }, reply2, at) => {
    const operationId = createOpaqueToken();
    reply2({ result: "started", operationId });
    const subscription = upstream.getBody(at).subscribe(
      ({ block: { extrinsics: value } }) => {
        operations.delete(operationId);
        notification("chainHead_v1_body", followId, {
          event: "operationBodyDone",
          operationId,
          value
        });
      },
      (e) => {
        operations.delete(operationId);
        console.error(e);
        notification("chainHead_v1_body", followId, {
          event: "operationError",
          operationId,
          error: ""
          // TODO: figure this out
        });
      }
    );
    if (!subscription.closed)
      operations.set(operationId, () => {
        subscription.unsubscribe();
        operations.delete(operationId);
      });
  };
  const stg = ({ operations, id: followId }, reply2, at, items) => {
    const operationId = createOpaqueToken();
    reply2({ result: "started", operationId });
    const innerNotifiaction = (msg) => {
      notification("chainHead_v1_storage", followId, msg);
    };
    const subscription = getStg$(upstream, at, items).pipe(
      rxjs.finalize(() => {
        operations.delete(operationId);
      })
    ).subscribe(
      (items2) => {
        innerNotifiaction({
          event: "operationStorageItems",
          operationId,
          items: items2
        });
      },
      (e) => {
        console.error(e);
        innerNotifiaction({
          event: "operationError",
          operationId,
          error: ""
          // TODO: figure this out
        });
      },
      () => {
        innerNotifiaction({
          event: "operationStorageDone",
          operationId
        });
      }
    );
    if (!subscription.closed)
      operations.set(operationId, () => {
        subscription.unsubscribe();
      });
  };
  return (rId, method, params) => {
    if (method === chainHeadMethods.follow) return follow(rId);
    const [followId, ...rest] = params;
    const ctx = subscriptions.get(followId);
    if (!ctx) return err(rId, -32602, "Ivalid followSubscription");
    const innerReply = (value) => {
      reply(rId, value);
    };
    switch (method) {
      case chainHeadMethods.unfollow:
        return unfollow(rId, followId);
      case chainHeadMethods.stopOperation:
        return stopOperation(rId, followId, rest[0]);
      case chainHeadMethods.unpin: {
        const [hashOrHashes] = rest;
        if ((Array.isArray(hashOrHashes) ? hashOrHashes : [hashOrHashes]).some(
          (hash) => typeof hash !== "string"
        ))
          return err(rId, -32602, "Invalid args");
        return unpin(ctx, innerReply, hashOrHashes);
      }
      default: {
        const [at, ...other] = rest;
        if (!ctx.up.isPinned(at)) return err(rId, -32801, "Block not pinned");
        switch (method) {
          case chainHeadMethods.header:
            return header(ctx, innerReply, at);
          case chainHeadMethods.body:
            return body(ctx, innerReply, at);
          case chainHeadMethods.call: {
            const [method2, data] = other;
            if (typeof method2 !== "string" || typeof data !== "string")
              return err(rId, -32602, "Invalid args");
            return call(ctx, innerReply, at, method2, data);
          }
          case chainHeadMethods.storage: {
            const [items] = other;
            return areItemsValid(items) ? stg(ctx, innerReply, at, items) : err(rId, -32602, "Invalid args");
          }
        }
      }
    }
    throw null;
  };
};

const transactionMethods = Object.fromEntries(
  ["broadcast", "stop"].map((key) => [key, `transaction_v1_${key}`])
);
const createTransactionFns = (upstream, reply) => {
  return (rId, method, args) => {
    const ongoing = /* @__PURE__ */ new Map();
    if (method === transactionMethods.stop) {
      const [token] = args;
      const sub = ongoing.get(token);
      sub?.unsubscribe();
      ongoing.delete(token);
      reply(rId, null);
    } else if (method === transactionMethods.broadcast) {
      const token = createOpaqueToken();
      ongoing.set(
        token,
        upstream.obsRequest("author_submitExtrinsic", args).pipe(
          rxjs.catchError((_, source) => rxjs.concat(rxjs.timer(5e3), source)),
          rxjs.takeUntil(
            upstream.finalized$.pipe(
              rxjs.ignoreElements(),
              rxjs.catchError(() => {
                ongoing.delete(token);
                return [null];
              })
            )
          )
        ).subscribe()
      );
      reply(rId, token);
    } else {
      throw null;
    }
  };
};

const archiveMethods = Object.fromEntries(
  [
    "body",
    "call",
    "finalizedHeight",
    "genesisHash",
    "hashByHeight",
    "header",
    "stopStorage",
    "storage"
  ].map((key) => [key, `archive_v1_${key}`])
);
const createArchive = (upstream, reply, err, notification) => {
  const subscriptions = /* @__PURE__ */ new Map();
  const stg = (reply2, at, items) => {
    const subId = createOpaqueToken();
    reply2(subId);
    const innerNotifiaction = (result) => {
      notification("archive_v1_storageEvent", subId, result);
    };
    const subscription = getStg$(upstream, at, items).pipe(
      rxjs.finalize(() => {
        subscriptions.delete(subId);
      })
    ).subscribe(
      (items2) => {
        items2.forEach(
          (item) => innerNotifiaction({ event: "storage", ...item })
        );
      },
      (e) => {
        console.error(e);
        innerNotifiaction({ event: "storageError", error: "" });
      },
      () => {
        innerNotifiaction({ event: "storageDone" });
      }
    );
    if (!subscription.closed)
      subscriptions.set(subId, () => {
        subscription.unsubscribe();
      });
  };
  return (rId, name, params) => {
    const innerReply = (value) => {
      reply(rId, value);
    };
    const obsReply = (input) => {
      input.subscribe({
        next: innerReply,
        error: (e) => {
          err(rId, e.code ?? -1, e.error ?? "");
        }
      });
    };
    const [firstArg, secondArg, thirdArg] = params;
    switch (name) {
      case archiveMethods.body:
        return obsReply(upstream.getBody(firstArg));
      case archiveMethods.call:
        return obsReply(
          upstream.runtimeCall(firstArg, secondArg, thirdArg).pipe(rxjs.map((value) => ({ success: true, value })))
        );
      case archiveMethods.finalizedHeight:
        return obsReply(
          upstream.finalized$.pipe(
            rxjs.map((x) => x.number),
            rxjs.take(1)
          )
        );
      case archiveMethods.genesisHash:
        return obsReply(upstream.genesisHash);
      case archiveMethods.hashByHeight:
        return obsReply(upstream.getBlockHash$(firstArg));
      case archiveMethods.header:
        return obsReply(
          upstream.getHeader$(firstArg).pipe(rxjs.map((h) => h.header))
        );
      case archiveMethods.stopStorage: {
        const sub = subscriptions.get(firstArg);
        return sub ? sub() : err(rId, -32602, "Invalid args");
      }
      case archiveMethods.storage:
        return areItemsValid(secondArg) ? stg(innerReply, firstArg, secondArg) : err(rId, -32602, "Invalid args");
    }
    throw null;
  };
};

const withNumericIds = (base) => (onMsg) => {
  let nextId = 0;
  const numberToOriginal = /* @__PURE__ */ new Map();
  const { send: originalSend, disconnect } = base((msg) => {
    const { id, ...rest } = JSON.parse(msg);
    let actualMsg = msg;
    if (numberToOriginal.has(id)) {
      actualMsg = JSON.stringify({ ...rest, id: numberToOriginal.get(id) });
      numberToOriginal.delete(id);
    }
    onMsg(actualMsg);
  });
  return {
    send: (msg) => {
      const parsedMsg = JSON.parse(msg);
      let actualMsg = msg;
      if ("id" in parsedMsg) {
        const id = nextId++;
        numberToOriginal.set(id, parsedMsg.id);
        actualMsg = JSON.stringify({ ...parsedMsg, id });
      }
      originalSend(actualMsg);
    },
    disconnect
  };
};

const supportedMethods = [
  chainSpecMethods,
  archiveMethods,
  chainHeadMethods,
  transactionMethods
].map((methods) => Object.values(methods)).flat();
const createDownstream = () => (upstreamProvider) => {
  const upstream = createUpstream(withNumericIds(upstreamProvider));
  return (onMessage) => {
    const jsonRpc = (input) => onMessage(
      JSON.stringify({
        jsonrpc: "2.0",
        ...input
      })
    );
    const reply = (id, result) => {
      jsonRpc({ id, result });
    };
    const err = (id, code, message) => {
      jsonRpc({ id, error: { code, message } });
    };
    const notification = (method, subscription, result) => {
      jsonRpc({ method, params: { subscription, result } });
    };
    const groups = {
      chainSpec: createChainSpec(upstream, reply, err),
      chainHead: createChainHead(upstream, reply, err, notification),
      archive: createArchive(upstream, reply, err, notification),
      transaction: createTransactionFns(upstream, reply)
    };
    return {
      send: (msg) => {
        let parsedMsg = null;
        try {
          parsedMsg = JSON.parse(msg);
        } catch {
        }
        if (!parsedMsg) return;
        const { id, method, params } = parsedMsg;
        if (id !== null && typeof id !== "string" && typeof id !== "number" || typeof method !== "string") {
          console.warn(`Invalid message:
${msg}`);
          return;
        }
        if (method === "rpc_methods") {
          return upstream.methods.subscribe(
            ({ methods }) => {
              reply(id, {
                methods: [
                  ...supportedMethods,
                  ...methods.filter(
                    (method2) => !supportedMethods.includes(method2)
                  )
                ]
              });
            },
            (e) => {
              console.error(e);
              err(id, -32602, "Invalid");
            }
          );
        }
        const [groupName] = method.split("_");
        if (groupName in groups) {
          try {
            return groups[groupName](
              id,
              method,
              params
            );
          } catch (e) {
            if (e !== null) throw e;
          }
        }
        upstream.request(
          method,
          params,
          (value) => {
            reply(id, value);
          },
          (e) => {
            err(id, e?.code || -1, e?.message || "");
          }
        );
      },
      disconnect: () => {
        upstream.disconnect();
      }
    };
  };
};

const withLegacy = createDownstream;

exports.withLegacy = withLegacy;
//# sourceMappingURL=index.js.map
